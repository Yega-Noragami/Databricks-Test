{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61ca74de-a5d5-48ed-bc79-6e5f42547dc3",
   "metadata": {},
   "source": [
    "# Data Analysis project using pyspark \n",
    "\n",
    "#### Tasks Needed to be done: \n",
    "1. Data Ingestion\n",
    "2. Data Transformation \n",
    "3. Data Manipulation \n",
    "4. Data Visualisation \n",
    "5. Data Storage \n",
    "\n",
    "\n",
    "#### Bonus Task: \n",
    "1. Repeat the data manipulation operations using Spark SQL using SQL Statements (e.g.:\n",
    "“SELECT Salary FROM employees ....“\n",
    "\n",
    "2. Write down how would you execute the Data Storage steps storing the data to:\n",
    "- Azure CosmosDB\n",
    "- Parquet in Azure Storage\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e81ff7-062b-4e55-8094-8e75bd8e5d84",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries and set up a spark session "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "794f8fc1-bd2e-40ee-8143-ac3b3625778e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pyspark \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, sum as spark_sum, desc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15cfe33c-3845-4ce8-ac07-7d31436f51fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"EmployeeDataAnalysis\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077bb06d-00a2-4ed7-b499-3bd601fa0dd3",
   "metadata": {},
   "source": [
    "#  1. DATA Ingestion \n",
    "Load the provided CSV into a DataFrame in a Databricks notebook. The CSV\n",
    "contains fields: `EmployeeID, FirstName, LastName, BirthDate, Department,\n",
    "Salary`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0e34704-e964-4dd5-8cfe-4f6c8212b87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------+----------+----------+------+\n",
      "|EmployeeID|FirstName| LastName| BirthDate|Department|Salary|\n",
      "+----------+---------+---------+----------+----------+------+\n",
      "|         1|     John|      Doe|01/12/1980|     Sales| 70000|\n",
      "|         2|     Jane|    Smith|14/07/1985| Marketing| 80000|\n",
      "|         3|   Oliver|  Johnson|30/06/1990|        IT| 90000|\n",
      "|         4|     Emma| Williams|21/01/1989|        HR| 75000|\n",
      "|         5|     Liam|    Brown|05/03/1987|     Sales| 85000|\n",
      "|         6|      Ava|   Garcia|22/04/1995|      NULL| 82000|\n",
      "|         7|  William| Martinez|10/02/1981|        IT| 77000|\n",
      "|         8|   Sophia| Robinson|12/09/1988| Marketing| 94000|\n",
      "|         9|    James|    Clark|19/06/1982|      NULL| 81000|\n",
      "|        10|Charlotte|Rodriguez|08/07/1991|        HR| 88000|\n",
      "|        11| Benjamin|    Lewis|30/11/1983|     Sales| 95000|\n",
      "|        12|      Mia|      Lee|17/02/1986| Marketing| 78000|\n",
      "|        13|    Ethan|   Walker|25/08/1992|      NULL| 92000|\n",
      "|        14|   Harper|     Hall|31/05/1993|     Sales| 89000|\n",
      "|        15|     Noah|    Allen|12/01/1984|        IT| 76000|\n",
      "|        16|   Amelia|    Young|13/02/1994| Marketing| 93000|\n",
      "|        17|    Jacob|Hernandez|27/04/1987|     Sales| 91000|\n",
      "|        18| Isabella|     King|03/12/1992|      NULL| 74000|\n",
      "|        19|     Luke|   Wright|22/01/1985|        IT| 86000|\n",
      "|        20|   Evelyn|    Lopez|05/03/1990| Marketing| 83000|\n",
      "+----------+---------+---------+----------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First We are going to perform Data Ingestion \n",
    "\n",
    "# Set up the path to employees\n",
    "data_path = \"employees.csv\"\n",
    "\n",
    "# Load CSV data into a DataFrame\n",
    "employees_df = spark.read.csv(data_path, header=True ,inferSchema=True,  sep=';')\n",
    "\n",
    "# View Employees Table \n",
    "employees_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9f6b8e8-efa4-4117-ab65-f3efaebf37da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- EmployeeID: integer (nullable = true)\n",
      " |-- FirstName: string (nullable = true)\n",
      " |-- LastName: string (nullable = true)\n",
      " |-- BirthDate: string (nullable = true)\n",
      " |-- Department: string (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initial Data Screening \n",
    "employees_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5b3dd0-85f9-47db-a203-8841bea8a164",
   "metadata": {},
   "source": [
    "# 2. Data Transformation \n",
    "\n",
    "Any employee record with an empty value in the 'Department' column should\n",
    "be assigned to a department named 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c412b25e-abec-47ab-ba31-97da616ff394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------+----------+----------+------+\n",
      "|EmployeeID|FirstName| LastName| BirthDate|Department|Salary|\n",
      "+----------+---------+---------+----------+----------+------+\n",
      "|         1|     John|      Doe|01/12/1980|     Sales| 70000|\n",
      "|         2|     Jane|    Smith|14/07/1985| Marketing| 80000|\n",
      "|         3|   Oliver|  Johnson|30/06/1990|        IT| 90000|\n",
      "|         4|     Emma| Williams|21/01/1989|        HR| 75000|\n",
      "|         5|     Liam|    Brown|05/03/1987|     Sales| 85000|\n",
      "|         6|      Ava|   Garcia|22/04/1995|     Other| 82000|\n",
      "|         7|  William| Martinez|10/02/1981|        IT| 77000|\n",
      "|         8|   Sophia| Robinson|12/09/1988| Marketing| 94000|\n",
      "|         9|    James|    Clark|19/06/1982|     Other| 81000|\n",
      "|        10|Charlotte|Rodriguez|08/07/1991|        HR| 88000|\n",
      "|        11| Benjamin|    Lewis|30/11/1983|     Sales| 95000|\n",
      "|        12|      Mia|      Lee|17/02/1986| Marketing| 78000|\n",
      "|        13|    Ethan|   Walker|25/08/1992|     Other| 92000|\n",
      "|        14|   Harper|     Hall|31/05/1993|     Sales| 89000|\n",
      "|        15|     Noah|    Allen|12/01/1984|        IT| 76000|\n",
      "|        16|   Amelia|    Young|13/02/1994| Marketing| 93000|\n",
      "|        17|    Jacob|Hernandez|27/04/1987|     Sales| 91000|\n",
      "|        18| Isabella|     King|03/12/1992|     Other| 74000|\n",
      "|        19|     Luke|   Wright|22/01/1985|        IT| 86000|\n",
      "|        20|   Evelyn|    Lopez|05/03/1990| Marketing| 83000|\n",
      "+----------+---------+---------+----------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees_df = employees_df.na.fill(\"Other\", [\"Department\"])\n",
    "\n",
    "#Updated Employees Table \n",
    "employees_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06b2ec9-da8f-4d8c-9169-1d0da8429014",
   "metadata": {},
   "source": [
    "# Data Manipulation \n",
    "\n",
    "• Get the total salaries (sum) in the company.\n",
    "\n",
    "• Create a new data frame representing the total salary (sum) per department.\n",
    "\n",
    "• Generate a list of the top 5 highest-paid employees in the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb61c763-4ca5-4271-ac9d-cc9bf6ab2bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Get the total salaries (sum) in the company\n",
    "total_salaries = employees_df.agg(spark_sum(\"Salary\")).first()[0]\n",
    "\n",
    "# Create a new data frame representing the total salary (sum) per department \n",
    "department_salaries = (\n",
    "    employees_df.groupBy(\"Department\")\n",
    "    .agg(spark_sum(\"Salary\").alias(\"Total_Salary\"))\n",
    "    .sort(col(\"Department\"))\n",
    ")\n",
    "\n",
    "# Generate a list of the top 5 highest-paid employees in the company  \n",
    "top_paid_employees = employees_df.sort(desc(\"Salary\")).limit(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d3f482-eda7-432c-87b5-444920e90ec8",
   "metadata": {},
   "source": [
    "# 4. Data Vizualisation \n",
    "\n",
    "• Print the total salaries (sum) in the company.\n",
    "\n",
    "• Print the dataframe with salaries (sum) per department.\n",
    "\n",
    "• Print the datafrma with the top 5 highest-paid employees in the company.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92e8df1f-6c5f-44c7-82cc-db0223697640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Salaries Sum of employees: 1679000\n",
      "\n",
      "Total Salaries Per department: \n",
      "\n",
      "+----------+------------+\n",
      "|Department|Total_Salary|\n",
      "+----------+------------+\n",
      "|        HR|      163000|\n",
      "|        IT|      329000|\n",
      "| Marketing|      428000|\n",
      "|     Other|      329000|\n",
      "|     Sales|      430000|\n",
      "+----------+------------+\n",
      "\n",
      "\n",
      "Top 5 Paid employees: \n",
      "\n",
      "+----------+---------+---------+----------+----------+------+\n",
      "|EmployeeID|FirstName| LastName| BirthDate|Department|Salary|\n",
      "+----------+---------+---------+----------+----------+------+\n",
      "|        11| Benjamin|    Lewis|30/11/1983|     Sales| 95000|\n",
      "|         8|   Sophia| Robinson|12/09/1988| Marketing| 94000|\n",
      "|        16|   Amelia|    Young|13/02/1994| Marketing| 93000|\n",
      "|        13|    Ethan|   Walker|25/08/1992|     Other| 92000|\n",
      "|        17|    Jacob|Hernandez|27/04/1987|     Sales| 91000|\n",
      "+----------+---------+---------+----------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#------- DATA Vizualisation ----------\n",
    "\n",
    "print('Total Salaries Sum of employees:',total_salaries)\n",
    "\n",
    "print('\\nTotal Salaries Per department: \\n')\n",
    "department_salaries.show()\n",
    "\n",
    "print('\\nTop 5 Paid employees: \\n')\n",
    "top_paid_employees.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3120a97e-5fcc-456b-92e9-6431f46f020f",
   "metadata": {},
   "source": [
    "# 5. Data Storage \n",
    "\n",
    "Store the original employees dataframe partitioned by `Department` using\n",
    "Parquet format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c45240c-8211-4257-b2b1-bf84bb950755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to Parquet format, partitioned by Department\n",
    "employees_df.write.mode(\"overwrite\").parquet(\"department.parquet\", partitionBy=\"Department\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "264915e8-d215-4bc9-af7d-773163b04946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------+----------+------+----------+\n",
      "|EmployeeID|FirstName| LastName| BirthDate|Salary|Department|\n",
      "+----------+---------+---------+----------+------+----------+\n",
      "|         1|     John|      Doe|01/12/1980| 70000|     Sales|\n",
      "|         5|     Liam|    Brown|05/03/1987| 85000|     Sales|\n",
      "|        11| Benjamin|    Lewis|30/11/1983| 95000|     Sales|\n",
      "|        14|   Harper|     Hall|31/05/1993| 89000|     Sales|\n",
      "|        17|    Jacob|Hernandez|27/04/1987| 91000|     Sales|\n",
      "|         2|     Jane|    Smith|14/07/1985| 80000| Marketing|\n",
      "|         8|   Sophia| Robinson|12/09/1988| 94000| Marketing|\n",
      "|        12|      Mia|      Lee|17/02/1986| 78000| Marketing|\n",
      "|        16|   Amelia|    Young|13/02/1994| 93000| Marketing|\n",
      "|        20|   Evelyn|    Lopez|05/03/1990| 83000| Marketing|\n",
      "|         3|   Oliver|  Johnson|30/06/1990| 90000|        IT|\n",
      "|         7|  William| Martinez|10/02/1981| 77000|        IT|\n",
      "|        15|     Noah|    Allen|12/01/1984| 76000|        IT|\n",
      "|        19|     Luke|   Wright|22/01/1985| 86000|        IT|\n",
      "|         6|      Ava|   Garcia|22/04/1995| 82000|     Other|\n",
      "|         9|    James|    Clark|19/06/1982| 81000|     Other|\n",
      "|        13|    Ethan|   Walker|25/08/1992| 92000|     Other|\n",
      "|        18| Isabella|     King|03/12/1992| 74000|     Other|\n",
      "|         4|     Emma| Williams|21/01/1989| 75000|        HR|\n",
      "|        10|Charlotte|Rodriguez|08/07/1991| 88000|        HR|\n",
      "+----------+---------+---------+----------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the Parquet data into a new DataFrame\n",
    "parquet_df = spark.read.parquet(\"department.parquet\")\n",
    "\n",
    "# View the parquet format file\n",
    "parquet_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cb67bc-7a14-4ffc-b6de-5b59dfad7e58",
   "metadata": {},
   "source": [
    "# BONUS REQUIREMENTS \n",
    "\n",
    "Repeat the data manipulation operations using Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cc75be0-d36b-4058-9741-e26cb90003ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "To use sql query syntax in Pyspark, first, we need to convert the spark data \n",
    "frame into a temporary view which will allow us to perform SQL actions. \n",
    "'''\n",
    "employees_df.createTempView(\"employees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f527e89-2941-4e6e-b2f6-d80f90d29857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|total_salary|\n",
      "+------------+\n",
      "|     1679000|\n",
      "+------------+\n",
      "\n",
      "+----------+------------+\n",
      "|Department|Total_Salary|\n",
      "+----------+------------+\n",
      "|        HR|      163000|\n",
      "|        IT|      329000|\n",
      "| Marketing|      428000|\n",
      "|     Other|      329000|\n",
      "|     Sales|      430000|\n",
      "+----------+------------+\n",
      "\n",
      "+----------+---------+---------+----------+----------+------+\n",
      "|EmployeeID|FirstName| LastName| BirthDate|Department|Salary|\n",
      "+----------+---------+---------+----------+----------+------+\n",
      "|        11| Benjamin|    Lewis|30/11/1983|     Sales| 95000|\n",
      "|         8|   Sophia| Robinson|12/09/1988| Marketing| 94000|\n",
      "|        16|   Amelia|    Young|13/02/1994| Marketing| 93000|\n",
      "|        13|    Ethan|   Walker|25/08/1992|     Other| 92000|\n",
      "|        17|    Jacob|Hernandez|27/04/1987|     Sales| 91000|\n",
      "+----------+---------+---------+----------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the total salaries (sum) in the company\n",
    "total_salaries_sql = spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT SUM(Salary) AS total_salary\n",
    "    FROM employees\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Create a new data frame representing the total salary (sum) per department\n",
    "department_salaries_sql = spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT Department, SUM(Salary) AS Total_Salary\n",
    "    FROM employees\n",
    "    GROUP BY Department\n",
    "    ORDER BY Department\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Generate a list of the top 5 highest-paid employees in the company\n",
    "top_paid_employees_sql = spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT *\n",
    "    FROM employees\n",
    "    ORDER BY Salary DESC\n",
    "    LIMIT 5;\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "total_salaries_sql.show()\n",
    "\n",
    "department_salaries_sql.show()\n",
    "\n",
    "top_paid_employees_sql.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311cb0e3-242b-4995-9e07-ac5d8f06177f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe4d8ea0-b81e-4b05-9f8f-b40989d95449",
   "metadata": {},
   "source": [
    "#### End of Assignment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1da2653-fad7-435b-bf7f-c03eb002993a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
